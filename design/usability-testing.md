# VRChatキャスト募集掲示板 ユーザビリティテスト計画

## ユーザビリティテスト概要

VRChatキャスト募集掲示板のUIデザインとユーザーエクスペリエンスを検証するためのユーザビリティテスト計画を策定します。実装前と実装後の両段階でテストを実施し、ユーザビリティの問題を特定・改善します。

## テスト目標

### 主要目標
1. **使いやすさの検証**: ユーザーが直感的に操作できるか
2. **タスク完了率の測定**: 主要機能の完了率を定量的に評価
3. **満足度の測定**: ユーザーの満足度とフラストレーション要因の特定
4. **アクセシビリティの確認**: 多様なユーザーが利用できるか

### 具体的目標
- 新規ユーザーの募集投稿完了率: 80%以上
- 募集検索→応募完了率: 85%以上
- タスク完了時間: 競合サービス比10%短縮
- ユーザー満足度: 5段階評価で4.0以上
- 主要操作の直感性: ヘルプなしで80%以上が完了

## テスト対象ユーザー

### ペルソナベースのテスト参加者

#### 1. イベント主催者層（35%）
```
年齢: 25-35歳
VRChat歴: 2年以上
技術スキル: 中～高
頻度: 月1回以上イベント開催
デバイス: PC（主）、スマートフォン
```

#### 2. キャスト志望者層（45%）
```
年齢: 18-28歳
VRChat歴: 6ヶ月以上
技術スキル: 低～中
頻度: 週2-3回VRChat利用
デバイス: PC、スマートフォン均等
```

#### 3. クリエイター層（20%）
```
年齢: 25-40歳
VRChat歴: 3年以上
技術スキル: 高
頻度: ほぼ毎日VRChat利用
デバイス: PC中心
```

### 参加者数
- **プロトタイプテスト**: 8-12名
- **アルファ版テスト**: 15-20名
- **ベータ版テスト**: 30-50名

## テスト方法

### 1. プロトタイプテスト（設計段階）

#### 実施時期
デザイン完成後、実装開始前

#### テスト手法
```
手法: ペーパープロトタイプ + 画面遷移テスト
時間: 60分/セッション
場所: オンライン（Discord + 画面共有）
記録: 画面録画 + 音声録音
観察者: UXデザイナー + 1名
```

#### テストタスク
```
1. 新規会員登録（5分）
2. プロフィール設定（8分）
3. 募集検索・フィルタリング（7分）
4. 募集詳細確認・応募（10分）
5. 新規募集投稿（15分）
6. 応募者管理（10分）
```

### 2. アルファ版テスト（実装初期）

#### 実施時期
基本機能実装完了後

#### テスト手法
```
手法: 実際のシステムを使用
時間: 90分/セッション
場所: ハイブリッド（対面 + オンライン）
記録: 画面録画 + 操作ログ + Think Aloud
観察者: UXデザイナー + 開発者
```

#### テストシナリオ
```
シナリオ1: 初回利用ユーザー
「VRChatでライブイベントに参加したいあなたは、司会者募集を見つけて応募してください」

シナリオ2: 主催者ユーザー
「あなたは撮影会を企画しています。スタッフ3名を募集してください」

シナリオ3: リピートユーザー
「過去に応募した結果を確認し、新しい募集にお気に入り登録してください」
```

### 3. ベータ版テスト（リリース前）

#### 実施時期
全機能実装完了後

#### テスト手法
```
手法: リモートユーザビリティテスト + アンケート
期間: 2週間
参加者: 実際のVRChatユーザー
記録: 自動ログ収集 + ユーザーレポート
フィードバック: 定期的なヒアリング
```

## 測定指標

### 定量的指標

#### タスク成功率
```
完全成功: エラーなしで完了
部分成功: 軽微なエラーで完了
失敗: 完了できない

目標値:
- 完全成功率: 70%以上
- 部分成功率: 20%以内
- 失敗率: 10%以下
```

#### タスク完了時間
```
測定方法: タスク開始から完了まで
分析: 平均時間、中央値、最大/最小値

目標値:
- 会員登録: 3分以内
- 募集検索: 2分以内
- 応募: 1分以内
- 募集投稿: 8分以内
```

#### エラー率
```
エラー分類:
- Critical: タスク完了不可
- Major: 大幅な回り道
- Minor: 軽微な迷い

目標値:
- Critical Error: 5%以下
- Major Error: 10%以下
- Minor Error: 20%以下
```

### 定性的指標

#### 満足度評価
```
評価方法: 5段階リッカート尺度
評価項目:
- 全体的な使いやすさ
- デザインの魅力度
- 機能の充実度
- 情報の見つけやすさ
- システムの信頼性

目標値: 全項目で平均4.0以上
```

#### System Usability Scale (SUS)
```
標準的な10項目のSUSスコア
目標値: 80点以上（上位10%レベル）

参考基準:
- 90点以上: 優秀
- 80-89点: 良好
- 70-79点: 普通
- 60-69点: やや問題
- 60点未満: 要改善
```

## テスト項目詳細

### 1. ナビゲーション・情報設計

#### 検証項目
```
✓ メインナビゲーションの理解度
✓ パンくずリストの有効性
✓ 検索機能の発見可能性
✓ カテゴリ分類の直感性
✓ 情報階層の適切性
```

#### 測定方法
```
- 目的のページへの到達率
- 迷った回数・時間
- ヘルプ利用頻度
- ユーザーの期待との一致度
```

### 2. フォーム・入力操作

#### 検証項目
```
✓ フォーム項目の理解しやすさ
✓ エラーメッセージの分かりやすさ
✓ 入力補助機能の有効性
✓ 必須/任意項目の明確さ
✓ 進捗表示の適切性
```

#### 測定方法
```
- 入力エラー発生率
- 入力時間
- ヘルプテキスト確認頻度
- フォーム離脱率
```

### 3. レスポンシブデザイン

#### 検証項目
```
✓ モバイルでの操作性
✓ タッチターゲットサイズ
✓ 画面回転時の対応
✓ 異なる画面サイズでの表示
✓ モバイル特有の機能活用
```

#### 測定方法
```
- デバイス別タスク完了率
- 操作ミス頻度
- スクロール・ズーム頻度
- デバイス満足度比較
```

### 4. アクセシビリティ

#### 検証項目
```
✓ キーボードナビゲーション
✓ スクリーンリーダー対応
✓ カラーコントラスト
✓ フォントサイズ調整対応
✓ 音声・動画の代替テキスト
```

#### 測定方法
```
- 支援技術利用者のタスク完了率
- WCAG 2.1 チェックリスト
- アクセシビリティ自動テスト
- 当事者ユーザーからのフィードバック
```

## テスト実施プロセス

### 事前準備

#### 1. 参加者リクルーティング（2週間前）
```
- VRChatコミュニティでの募集
- SNSでの告知
- 既存ユーザーへの案内
- 謝礼設定（Amazonギフト券等）
```

#### 2. テスト環境準備（1週間前）
```
- テスト用アカウント作成
- シナリオ・タスク最終確認
- 録画・記録ツール準備
- バックアップ計画
```

#### 3. パイロットテスト（3日前）
```
- 内部スタッフでのテスト実施
- タイミング・手順の確認
- 技術的問題の解決
- シナリオの微調整
```

### テスト当日

#### セッション構成（90分）
```
1. 導入・説明（10分）
   - 目的説明、同意取得
   - Think Aloud法の説明
   - 緊張緩和

2. 事前質問（5分）
   - 背景情報収集
   - 事前期待の確認

3. タスク実行（60分）
   - 6つのタスクを順次実行
   - 観察・記録

4. 事後インタビュー（10分）
   - 感想・意見収集
   - 改善提案聴取

5. アンケート記入（5分）
   - SUSスケール等
   - 満足度評価
```

### 事後分析

#### 1. データ整理（1日後）
```
- 録画データの整理
- 定量データの集計
- 定性データの分類
- 問題点のリスト化
```

#### 2. 分析・レポート作成（3日後）
```
- パターン分析
- 重要度・緊急度マトリクス
- 改善提案の策定
- ステークホルダー向けレポート
```

#### 3. 改善計画策定（1週間後）
```
- 優先度付け
- 実装計画
- 再テスト計画
- リリーススケジュール調整
```

## 改善サイクル

### 継続的改善プロセス

#### 短期改善（1-2週間）
```
- Critical/Majorエラーの修正
- 明らかなユーザビリティ問題の解決
- 簡単に実装できる改善
```

#### 中期改善（1-2ヶ月）
```
- UI/UXの大幅な見直し
- 新機能の追加・既存機能の改修
- パフォーマンス最適化
```

#### 長期改善（3ヶ月以上）
```
- 抜本的な設計見直し
- 新しいユーザーニーズへの対応
- 技術的負債の解消
```

### 成功基準

#### リリース判定基準
```
必須基準:
- Critical Error 5%以下
- タスク完全成功率 70%以上
- SUSスコア 75以上

推奨基準:
- Major Error 10%以下
- ユーザー満足度 4.0以上
- アクセシビリティ WCAG 2.1 AA準拠
```

## ツール・リソース

### テストツール
```
画面録画: OBS Studio, Loom
リモートテスト: UserTesting, Maze
アンケート: Google Forms, Typeform
分析: Google Analytics, Hotjar
アクセシビリティ: axe, WAVE
```

### 予算計画
```
参加者謝礼: 1,000円×50名 = 50,000円
ツール利用料: 月額10,000円×3ヶ月 = 30,000円
外部専門家: 50,000円×2回 = 100,000円
合計: 約180,000円
```

このユーザビリティテスト計画により、ユーザー中心のデザイン改善を継続的に実施し、VRChatコミュニティにとって真に使いやすいサービスを提供できます。